# qa_tools\generate_lexicon_regression_tests.py
"""
qa_tools/generate_lexicon_regression_tests.py
--------------------------------------------

Generate a pytest module that performs *regression tests* on the lexicon
files under `data/lexicon/`.

What it does
============

- Scans `data/lexicon/` for `*.json` lexicon files.
- For each file:
    - Loads the JSON.
    - Reads the keys under "lemmas".
    - Sorts them and records the list.
- Writes `qa/test_lexicon_regression.py` containing:
    - A constant SNAPSHOTS = { "en_lexicon.json": [...], ... }
    - A single test that:
        - Reloads each lexicon file,
        - Recomputes the sorted lemma list,
        - Asserts that it exactly matches the snapshot.

Usage
=====

From project root:

    python qa_tools/generate_lexicon_regression_tests.py

Then, in your regular QA run:

    pytest

If you intentionally change the lexicon (add/remove/rename lemmas),
pytest will fail until you regenerate the regression tests by rerunning
this script.

Notes
=====

- This script does *not* validate lexicon contents; it only guards
  against unintended changes to lemma inventories.
- It ignores `data/lexicon_schema.json` and any JSON file whose name
  starts with "." or "_".
"""

from __future__ import annotations

import json
import os
import sys
from typing import Dict, List

# Ensure project root on path
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from utils.logging_setup import get_logger, init_logging  # type: ignore  # noqa: E402

LEXICON_DIR = os.path.join(PROJECT_ROOT, "data", "lexicon")
QA_DIR = os.path.join(PROJECT_ROOT, "qa")
OUTPUT_TEST_FILE = os.path.join(QA_DIR, "test_lexicon_regression.py")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _list_lexicon_files(lexicon_dir: str) -> List[str]:
    """
    Return a sorted list of lexicon JSON files (absolute paths) in lexicon_dir,
    excluding schema / special files.
    """
    files: List[str] = []
    for entry in os.listdir(lexicon_dir):
        if not entry.lower().endswith(".json"):
            continue
        if entry.startswith(".") or entry.startswith("_"):
            continue
        if entry == "lexicon_schema.json":
            continue
        full = os.path.join(lexicon_dir, entry)
        if os.path.isfile(full):
            files.append(full)
    files.sort()
    return files


def _collect_snapshots(files: List[str]) -> Dict[str, List[str]]:
    """
    Build a mapping from relative lexicon filename (e.g. 'en_lexicon.json')
    to a sorted list of lemma keys.
    """
    log = get_logger(__name__)
    snapshots: Dict[str, List[str]] = {}

    for path in files:
        rel_name = os.path.basename(path)
        log.info("Collecting lemmas from %s", rel_name)

        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        lemmas = data.get("lemmas")
        if not isinstance(lemmas, dict):
            log.warning(
                "File %s has no top-level 'lemmas' object; treating as empty.",
                rel_name,
            )
            snapshots[rel_name] = []
            continue

        keys = sorted(lemmas.keys())
        snapshots[rel_name] = keys

    return snapshots


def _render_python_literal(obj: object, indent: int = 4) -> str:
    """
    Render Python literals (dict/list/str) in a reasonably pretty way
    for embedding in the generated test file.

    This avoids pulling in `pprint` and gives us fully deterministic,
    compact output.
    """
    # We rely on json.dumps for simple, deterministic literal formatting.
    # For our purposes (strings, lists, dicts with simple keys) this is fine.
    return json.dumps(obj, ensure_ascii=False, indent=indent)


def _write_test_module(snapshots: Dict[str, List[str]], out_path: str) -> None:
    """
    Write the pytest regression module to `out_path`.
    """
    rel_lexicon_dir = os.path.relpath(LEXICON_DIR, PROJECT_ROOT)
    header = f"""\"\"\"Auto-generated lexicon regression tests.

DO NOT EDIT BY HAND.

This file was generated by:
    qa_tools/generate_lexicon_regression_tests.py

It captures the *current* set of lemma keys per lexicon file in
`{rel_lexicon_dir}`. The tests ensure that future changes to those
lexicon files do not silently alter lemma inventories.

If you intentionally modify the lexicon (add/remove/rename lemmas),
you should re-run the generator:

    python qa_tools/generate_lexicon_regression_tests.py
\"\"\"


from __future__ import annotations

import json
import os

import pytest

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LEXICON_DIR = os.path.join(PROJECT_ROOT, "data", "lexicon")


# Snapshot of lemma keys per lexicon file (basename → sorted lemma list)
SNAPSHOTS = \
"""

    body = _render_python_literal(snapshots, indent=4)
    tests = """

@pytest.mark.parametrize("filename", sorted(SNAPSHOTS.keys()))
def test_lexicon_lemma_inventory_is_stable(filename: str) -> None:
    \"\"\"Ensure that the set of lemma keys matches the recorded snapshot.

    This guards against unintended changes in lexicon inventories.
    If you intended to change the lexicon, regenerate this file by
    running `qa_tools/generate_lexicon_regression_tests.py`.
    \"\"\"  # noqa: D401
    path = os.path.join(LEXICON_DIR, filename)
    assert os.path.isfile(path), f"Lexicon file not found: {path}"

    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    lemmas = data.get("lemmas")
    if not isinstance(lemmas, dict):
        current = []
    else:
        current = sorted(lemmas.keys())

    expected = SNAPSHOTS[filename]
    assert current == expected, (
        f"Lexicon lemma inventory changed for {filename}.\\n"
        f"  Expected: {len(expected)} lemmas\\n"
        f"  Current:  {len(current)} lemmas\\n"
        "If this change was intentional, regenerate the regression tests."
    )
"""

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(header)
        f.write(body)
        f.write(tests)


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------


def main(argv: list[str] | None = None) -> None:
    init_logging()
    log = get_logger(__name__)

    if not os.path.isdir(LEXICON_DIR):
        log.error("Lexicon directory not found: %s", LEXICON_DIR)
        print(f"❌ Lexicon directory not found: {LEXICON_DIR}")
        sys.exit(1)

    files = _list_lexicon_files(LEXICON_DIR)
    if not files:
        log.error("No lexicon JSON files found in %s", LEXICON_DIR)
        print(f"❌ No lexicon JSON files found in: {LEXICON_DIR}")
        sys.exit(1)

    snapshots = _collect_snapshots(files)
    _write_test_module(snapshots, OUTPUT_TEST_FILE)

    rel_out = os.path.relpath(OUTPUT_TEST_FILE, PROJECT_ROOT)
    print(f"✅ Generated regression tests in {rel_out}")
    log.info("Generated regression tests in %s", rel_out)


if __name__ == "__main__":
    main()
