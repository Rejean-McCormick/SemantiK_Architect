# ai_services/judge.py
import json
import logging
import re
from typing import Dict, Any, Optional

import httpx
from google import genai
from google.genai import types

from app.shared.config import settings
from ai_services.prompts import JUDGE_SYSTEM_PROMPT

logger = logging.getLogger(settings.OTEL_SERVICE_NAME)


def _looks_like_auth_error(msg: str) -> bool:
    m = (msg or "").upper()
    return (
        "API_KEY_INVALID" in m
        or "API KEY NOT VALID" in m
        or "PLEASE PASS A VALID API KEY" in m
        or "UNAUTHENTICATED" in m
        or "PERMISSION_DENIED" in m
        or "401" in m
        or "403" in m
    )


class JudgeAgent:
    """
    The Judge: A strict QA evaluator for Natural Language Generation.
    1. Evaluates outputs against Gold Standard data.
    2. Auto-files GitHub issues for regressions (The Whistleblower).
    """

    def __init__(self):
        self.api_key = settings.GOOGLE_API_KEY
        self.model_name = settings.AI_MODEL_NAME
        self.github_token = settings.GITHUB_TOKEN
        self.repo_url = settings.REPO_URL

        # google-genai client
        self._client: Optional[genai.Client] = None

        if self.api_key:
            try:
                # google-genai: Client(api_key=...)
                self._client = genai.Client(api_key=self.api_key)
            except Exception as e:
                logger.error(f"âŒ Judge init failed; disabling AI Judge. Error: {e}")
                self._client = None
        else:
            logger.warning("âš ï¸ GOOGLE_API_KEY not found. The Judge is presiding in silent mode.")

    def evaluate_case(self, generated_text: str, gold_case: Dict[str, Any]) -> Dict[str, Any]:
        """
        Compares the engine's output against the Gold Standard 'expected' string.

        Returns:
            Dict: { "score": 0.0-1.0, "verdict": "PASS/FAIL/SKIPPED/ERROR", "critique": "..." }
        """
        if not self._client:
            return {"score": 0, "verdict": "SKIPPED", "critique": "AI Agent disabled"}

        expected_text = gold_case.get("expected") or ""
        lang = gold_case.get("lang")
        intent = json.dumps(gold_case.get("intent"))

        # Fast pass: case-insensitive exact match
        if generated_text.strip().lower() == expected_text.strip().lower():
            return {"score": 1.0, "verdict": "PASS", "critique": "Exact match with Gold Standard."}

        user_prompt = f"""
**CONTEXT:**
Target Language: {lang}
Semantic Intent: {intent}

**COMPARISON:**
Gold Standard: "{expected_text}"
Actual Output: "{generated_text}"
"""

        try:
            # Prefer a strict JSON response to simplify parsing.
            response = self._client.models.generate_content(
                model=self.model_name,
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    system_instruction=JUDGE_SYSTEM_PROMPT,
                    temperature=0.0,
                    response_mime_type="application/json",
                ),
            )

            result = self._parse_json(getattr(response, "text", "") or "")

            # Auto-report regressions if configured
            if result.get("score", 0) < 0.8 and self.github_token:
                self._file_github_issue(gold_case, generated_text, result)

            return result

        except Exception as e:
            msg = str(e)
            logger.error(f"âŒ Judge evaluation failed: {msg}")

            # If auth/key is bad, disable judge for the rest of the run and SKIP
            if _looks_like_auth_error(msg):
                self._client = None
                return {"score": 0, "verdict": "SKIPPED", "critique": msg}

            return {"score": 0, "verdict": "ERROR", "critique": msg}

    def _file_github_issue(self, gold_case: Dict, actual: str, evaluation: Dict) -> None:
        """
        The Whistleblower: Files a GitHub issue when quality drops below threshold.
        """
        if "github.com" not in (self.repo_url or ""):
            return

        try:
            _, _, _, owner, repo = self.repo_url.rstrip("/").split("/")[:5]
            api_url = f"https://api.github.com/repos/{owner}/{repo}/issues"
        except ValueError:
            logger.error(f"Invalid REPO_URL format: {self.repo_url}")
            return

        title = f"Regression: {gold_case.get('lang')} - {gold_case.get('id')}"
        body = f"""
### ðŸš¨ Quality Regression Detected
**The Judge** has detected a failure in the Gold Standard test suite.

| Field | Value |
| :--- | :--- |
| **Test ID** | `{gold_case.get('id')}` |
| **Language** | `{gold_case.get('lang')}` |
| **Expected** | `{gold_case.get('expected')}` |
| **Actual** | `{actual}` |
| **Score** | `{evaluation.get('score')}` |

**Critique:**
> {evaluation.get('critique')}

*Auto-generated by Abstract Wiki Architect v2.0*
        """

        headers = {"Authorization": f"token {self.github_token}", "Accept": "application/vnd.github.v3+json"}

        try:
            check_res = httpx.get(api_url, headers=headers, params={"state": "open", "labels": "regression"})
            if check_res.status_code == 200:
                for issue in check_res.json():
                    if issue.get("title") == title:
                        logger.info(f"Existing issue found for {title}. Skipping.")
                        return

            res = httpx.post(
                api_url,
                headers=headers,
                json={"title": title, "body": body, "labels": ["regression", "automated", "judge"]},
            )
            if res.status_code == 201:
                logger.info(f"ðŸ“‚ GitHub Issue filed: {title}")
            else:
                logger.error(f"Failed to file issue: {res.text}")

        except Exception as e:
            logger.error(f"Whistleblower error: {e}")

    def _parse_json(self, text: str) -> Dict[str, Any]:
        """
        Robust JSON extraction from LLM output.
        """
        try:
            clean = re.sub(r"```json|```", "", (text or "")).strip()
            return json.loads(clean)
        except json.JSONDecodeError:
            logger.error(f"Judge output invalid JSON: {text}")
            return {"score": 0, "verdict": "JSON_ERROR", "critique": "Output parsing failed"}


# Global Singleton
judge = JudgeAgent()